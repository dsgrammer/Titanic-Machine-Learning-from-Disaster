setwd("C:/Users/dsgra/OneDrive/Documents/GitHub/Titanic-Machine-Learning-from-Disaster")
library(tidyverse)
train = read.csv('C:/Users/dsgra/OneDrive/Documents/GitHub/Titanic-Machine-Learning-from-Disaster/00 Data/train.csv',
na.strings = c(""), stringsAsFactors=TRUE)
test = read.csv('C:/Users/dsgra/OneDrive/Documents/GitHub/Titanic-Machine-Learning-from-Disaster/00 Data/test.csv',
na.strings = c(""), stringsAsFactors=TRUE)
#Data Preprocessing -------------------------------------------------------------------
#Convert columns into factors if they are factors
str(train)
train$Survived <- factor(train$Survived)
train$Pclass <- factor(train$Pclass)
#Before dropping columns and dealing with missing values take backup of original data
train_backup <- train
train[!complete.cases(train),]
#Cabin variable is nearly all NA, dropping as it is impossible to estimate cabin numbers
train <- subset(train,select = -c(Cabin))
#Age has 177 NAs, how to fill... Could replace with median,but let's wait and see.
table(train$Age, useNA = 'always')
summary(train$Age)
# table(train$PassengerId, useNA = 'always')
# table(train$Pclass, useNA = 'always')
# table(train$Name, useNA = 'always')
# table(train$Sex, useNA = 'always')
# table(train$SibSp, useNA = 'always')
# table(train$Parch, useNA = 'always')
# table(train$Ticket, useNA = 'always')
# table(train$Fare, useNA = 'always')
# Two passengers did not board the titanic, dropped
table(train$Embarked, useNA = 'always')
train <- train[!is.na(train$Embarked),]
str(test)
str(train)
test$Pclass <- factor(test$Pclass)
test_backup <- test
table(test$Cabin, useNA = 'always')
test <- subset(test,select = -c(Cabin))
#What to do about age...
table(train$Age, useNA = 'always')
summary(train$Age)
# Two passengers did not board the titanic, dropped
table(test$Embarked, useNA = 'always')
# test <- test %>%
#   add_column(empty_column = NA)
#----------------------------------------------------------------------------------
#Logistic regression
classifier = glm(formula = Survived ~ .,
family = binomial,
data = train)
View(classifier)
prob_pred = predict(classifier, type = 'response', newdata = test[-10])
prob_pred = predict(classifier, type = 'response', newdata = test[-11])
test <- test %>%
add_column(empty_column = NA)
prob_pred = predict(classifier, type = 'response', newdata = test[-11])
prob_pred = predict(classifier, type = 'response', newdata = test[-1])
View(test)
test <- test %>%
add_column(Survived = NULL)
View(test)
View(test)
test <- test %>%
add_column(Survived = NULL)
View(test)
?add_column
test <- add_column(test, .after = TRUE,)
View(test)
test <- add_column(.data = test, .after = TRUE,)
View(train)
test <- add_column(.data = test, .after = 'PassengerId',)
View(test)
test <- add_column(.data = test, .before = 'Pclass',)
test <- add_column(.data = test, .before = 'Pclass')
classifier = xgboost(data = data, label = label, nrounds = 10, objective = "binary:logistic")
# Fitting XGBoost to the Training set
library(xgboost)
data <- as.matrix(train[-2])
label <- as.numeric(train$Survived)
mode(data) <- 'double'
data <- as.matrix(train[-2])
classifier = xgboost(data = data, label = label, nrounds = 10, objective = "binary:logistic")
data <- as.matrix(train[-2])
View(data)
View(data)
